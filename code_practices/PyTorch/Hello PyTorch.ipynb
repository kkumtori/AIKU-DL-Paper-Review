{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM0q8j22Lvs/dNXAF+k1Noq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["해당 노트북은 고려대학교 정보대학 딥러닝 학회 [AIKU](https://github.com/AIKU-Official) D2D 과제 내용을 바탕으로 작성되었습니다."],"metadata":{"id":"RSBBnxdPNywP"}},{"cell_type":"markdown","source":["# 환경설정"],"metadata":{"id":"At5a4OBaP_fx"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","FOLDERNAME = '/AIKU/Github/AIKU-DL-Paper-Review/code_practices/PyTorch'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/datasets/\n","!bash get_datasets.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KK_kQqu5PKza","executionInfo":{"status":"ok","timestamp":1706458229219,"user_tz":-540,"elapsed":24265,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"b88539fa-3648-4036-e1b7-61e46c45c47c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/AIKU/Github/AIKU-DL-Paper-Review/code_practices/PyTorch/datasets\n","/content/drive/My Drive/AIKU/Github/AIKU-DL-Paper-Review/code_practices/PyTorch\n"]}]},{"cell_type":"code","source":["# GPU\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","USE_GPU=True\n","dtype=torch.float32\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device=torch.device('cuda')\n","else:\n","    device=torch.device('cpu')\n","\n","print('using device: ',device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y6FKDvE1RcGe","executionInfo":{"status":"ok","timestamp":1706458246034,"user_tz":-540,"elapsed":6431,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"845f2a93-93e4-4c74-962c-68bc4a6d76d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["using device:  cuda\n"]}]},{"cell_type":"markdown","source":["# 목차\n","\n","+ **Part1**.   준비\n","+ **Part2**.   Barebones PyTorch : 추상화 수준 1\n","+ **Part3**.   PyTorch Module API : 추상화 수준 2/ `nn.Module` 사용\n","+ **Part4**.   PyTorch Sequential API :추상화 수준 3/ `nn.Sequential` 사용\n","+ **Part5**.   CIFAR-10 open-ended challenge\n","+ **Part6**.   Pretrained model\n","\n","<br>\n","  \n","참고: PyTorch 추상화 수준별 비교\n","    \n","| API | 유연성 | 편의성 |\n","|---------------|-------------|-------------|\n","| Barebones | 높음 | 낮음 |\n","| `nn.Module` | 높음 | 중간 |\n","| `nn.Sequential` | 낮음 | 높음 |\n"],"metadata":{"id":"4jQgpb1iPzeK"}},{"cell_type":"markdown","source":["# **Part1. 준비**"],"metadata":{"id":"dYeTRUG0SOMw"}},{"cell_type":"markdown","source":[" The `torchvision.transforms` package provides tools for **preprocessing data and for performing data augmentation**;  \n"," here we set up a transform to preprocess the data *by subtracting the mean RGB value and dividing by the standard deviation of each RGB value*;    \n"," we've hardcoded the mean and std."],"metadata":{"id":"8NM3KBRNXDKI"}},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"6kUoITFofZb5"}},{"cell_type":"code","source":["# Preprocessing\n","transform=T.Compose([\n","    T.ToTensor(),\n","    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])"],"metadata":{"id":"hVrc1B6TSa76","executionInfo":{"status":"ok","timestamp":1706458248700,"user_tz":-540,"elapsed":3,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["We set up a Dataset object for each split (train / val / test);  \n","Datasets load training examples one at a time, so we wrap each Dataset in a `DataLoader` which iterates through the Dataset and forms minibatches.  \n","We divide the CIFAR-10 training set into train and val sets by passing a `Sampler` object to the DataLoader telling how it should sample from the underlying Dataset."],"metadata":{"id":"-H4eZ4jJXlfU"}},{"cell_type":"markdown","source":["## DataLoader"],"metadata":{"id":"ItwF9BlXfcQ0"}},{"cell_type":"code","source":["# DataLoader\n","NUM_TRAIN=49000\n","\n","cifar_10_train=dset.CIFAR10('./datasets',train=True,download=True,transform=transform)\n","loader_train=DataLoader(cifar_10_train,batch_size=64,\n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN))) #train 49,000장\n","\n","cifar_10_val=dset.CIFAR10('./datasets',train=True,download=True,transform=transform)\n","loader_val=DataLoader(cifar_10_train,batch_size=64,\n","                      sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN,50000))) #val1,000장\n","\n","cifar_10_test=dset.CIFAR10('./datasets',train=False,download=True,transform=transform)\n","loader_test=DataLoader(cifar_10_test,batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GYx38G-TBaB","executionInfo":{"status":"ok","timestamp":1706458264768,"user_tz":-540,"elapsed":14468,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"31809d13-a835-4ac4-878a-22c3a712ae15"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["## Original Images"],"metadata":{"id":"6gIERQBxfeRS"}},{"cell_type":"code","source":["def org_imshow(transformed_tensor):\n","    means=np.array([0.4914, 0.4822, 0.4465])\n","    stds=np.array([0.2023, 0.1994, 0.2010])\n","    tmp=[]\n","    for i in range(3):\n","        tmp.append(np.array((transformed_tensor[i]))*stds[i]+means[i])\n","    plt.imshow(np.transpose(tmp,(1,2,0)))"],"metadata":{"id":"rczf2TsOYPmA","executionInfo":{"status":"ok","timestamp":1706458264769,"user_tz":-540,"elapsed":7,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["for batch in loader_train:\n","    print('첫번째 배치 shape:',batch[0].shape)\n","    print('첫번째 배치 class:',batch[1].shape)\n","    org_imshow(batch[0][0])\n","    plt.title(cifar_10_train.classes[batch[1][0]])\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"id":"DASQOguBVZPB","executionInfo":{"status":"ok","timestamp":1706458265332,"user_tz":-540,"elapsed":569,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"db5b6aaa-26b7-43f7-b9f7-52d5e5895e66"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["첫번째 배치 shape: torch.Size([64, 3, 32, 32])\n","첫번째 배치 class: torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# **Part2. Barebones PyTorch**"],"metadata":{"id":"2SjHnxwVddT7"}},{"cell_type":"markdown","source":["## PyTorch Tensors: Flatten 함수"],"metadata":{"id":"Kcq4da63e0AJ"}},{"cell_type":"code","source":["def flatten(x):\n","    N=x.shape[0] # read in N,C,H,W\n","    return x.view(N,-1) # \"flatten\" the C * H * W values into a single vector per image"],"metadata":{"id":"f2b5sroNfot_","executionInfo":{"status":"ok","timestamp":1706458265332,"user_tz":-540,"elapsed":11,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def test_flatten():\n","    x=torch.arange(12).view(2,1,3,2)\n","    print('**Before flattening** \\n',x)\n","    print(x.shape)\n","    print('='*30+'>>')\n","    print('**After flattening** \\n',flatten(x))\n","    print(flatten(x).shape)"],"metadata":{"id":"FtPtPwQPgFUO","executionInfo":{"status":"ok","timestamp":1706458265333,"user_tz":-540,"elapsed":11,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["test_flatten()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08HwZnrrgf43","executionInfo":{"status":"ok","timestamp":1706458265333,"user_tz":-540,"elapsed":11,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"e3fc369b-dc01-418f-a865-f47bcfa8c549"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["**Before flattening** \n"," tensor([[[[ 0,  1],\n","          [ 2,  3],\n","          [ 4,  5]]],\n","\n","\n","        [[[ 6,  7],\n","          [ 8,  9],\n","          [10, 11]]]])\n","torch.Size([2, 1, 3, 2])\n","==============================>>\n","**After flattening** \n"," tensor([[ 0,  1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10, 11]])\n","torch.Size([2, 6])\n"]}]},{"cell_type":"markdown","source":["## 2-1.Barebones PyTorch: Two-Layer Network\n","여기에서는 이미지 데이터 배치에 대해 완전히 연결된 2계층 ReLU 네트워크의 포워드 패스를 수행하는 함수 `two_layer_fc`를 정의합니다.  \n","포워드 패스를 정의한 후에는 네트워크를 통해 0을 실행하여 충돌이 발생하지 않는지, 올바른 모양의 출력을 생성하는지 확인합니다.  \n","여기서 코드를 작성할 필요는 없지만 구현을 읽고 이해하는 것이 중요합니다."],"metadata":{"id":"HUD_-vnWgg62"}},{"cell_type":"code","source":["import torch.nn.functional as F # useful stateless functions\n","\n","def two_layer_fc(x,params):\n","    \"\"\"\n","    A fully-connected neural networks; the architecture is:\n","    NN is fully connected -> ReLU -> fully connected layer.\n","    Note that this function only defines the forward pass;\n","    PyTorch will take care of the backward pass for us.\n","\n","    The input to the network will be a minibatch of data, of shape\n","    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n","    and the output layer will produce scores for C classes.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n","      input data.\n","    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n","      w1 has shape (D, H) and w2 has shape (H, C).\n","\n","    Returns:\n","    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n","      the input data x.\n","    \"\"\"\n","\n","    # first we flatten the image\n","    x=flatten(x) # shape: [batch_size, C x H x W]->없어도 됨\n","\n","    w1,w2=params\n","\n","    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n","    # w2 have requires_grad=True, operations involving these Tensors will cause\n","    # PyTorch to build a computational graph, allowing automatic computation of\n","    # gradients. Since we are no longer implementing the backward pass by hand we\n","    # don't need to keep references to intermediate values.\n","    # you can also use `.clamp(min=0)`, equivalent to F.relu()\n","    x=F.relu(x.mm(w1)) #mm: matrix multiplication\n","    x=x.mm(w2)\n","    return x"],"metadata":{"id":"EwoDpGTBhSBR","executionInfo":{"status":"ok","timestamp":1706458265333,"user_tz":-540,"elapsed":9,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def two_layer_fc_test():\n","    hidden_layer_size=42\n","    x=torch.zeros((64,50),dtype=dtype)\n","    w1=torch.zeros((50,hidden_layer_size),dtype=dtype)\n","    w2=torch.zeros((hidden_layer_size,10),dtype=dtype)\n","    scores=two_layer_fc(x,[w1,w2])\n","    print(scores.size())\n","\n","two_layer_fc_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4GCNHVlisYQ","executionInfo":{"status":"ok","timestamp":1706458265759,"user_tz":-540,"elapsed":434,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"0b068662-4a2b-4c12-8008-a08371998b45"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}]},{"cell_type":"markdown","source":["## 2-2.Barebones PyTorch: Three-Layer ConvNet\n","\n","여기서는 3계층 Convolution 네트워크의 순방향 패스를 수행하는 `three_layer_convnet` 함수의 구현을 완료합니다. 위와 같이 네트워크에 0을 전달하여 구현을 즉시 테스트할 수 있습니다. 네트워크는 다음과 같은 구조를 가져야 합니다:\n","\n","1. `channel_1` 필터가 있는 Convolution 레이어(bias 포함), 각각 모양이 `KW1 x KH1`이고 zero padding 이 2입니다.\n","2. ReLU nonlinearity\n","3. `channel_2` 필터가 있는 Convolution 레이어(bias 포함), 각 필터의 모양이 `KW2 x KH2`이고 제로 패딩이 1입니다.\n","4. ReLU nonlinearity\n","5. bias가 있는 Fully-connected layer, C 클래스에 대한 점수를 생성합니다.\n","\n","Fully-connected layer 이후에는 **소프트맥스 활성화가 없음**에 유의하십시오: 이는 PyTorch의 교차 엔트로피 손실이 소프트맥스 활성화를 수행하기 때문이며, 이 단계를 번들로 묶으면 계산이 더 효율적이기 때문입니다."],"metadata":{"id":"oA_EbgVDj3jk"}},{"cell_type":"code","source":["def three_layer_convnet(x,params):\n","    \"\"\"\n","    Performs the forward pass of a three-layer convolutional network with the\n","    architecture defined above.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n","    - params: A list of PyTorch Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n","        for the first convolutional layer\n","      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n","        convolutional layer\n","      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n","        weights for the second convolutional layer\n","      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n","        convolutional layer\n","      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","\n","    Returns:\n","    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n","    \"\"\"\n","    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n","    scores = None\n","\n","    x=F.conv2d(input=x,weight=conv_w1,bias=conv_b1,padding=2) #1\n","    x=F.relu(x) #2\n","    x=F.conv2d(input=x,weight=conv_w2,bias=conv_b2,padding=1) #3\n","    x=F.relu(x) #4\n","    x=flatten(x)\n","    scores=x.mm(fc_w)+fc_b #5\n","\n","    return scores"],"metadata":{"id":"bag6R6rRkVWw","executionInfo":{"status":"ok","timestamp":1706458265759,"user_tz":-540,"elapsed":7,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def three_layer_convnet_test():\n","    x=torch.zeros((64,3,32,32),dtype=dtype)\n","\n","    conv_w1=torch.zeros((6,3,5,5),dtype=dtype) # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b1=torch.zeros((6,)) # out_channel\n","    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b2 = torch.zeros((9,))  # out_channel\n","\n","    fc_w = torch.zeros((9 * 32 * 32, 10))\n","    fc_b = torch.zeros(10)\n","\n","    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n","    print(scores.size())  # you should see [64, 10]\n","\n","three_layer_convnet_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shJMAgqEl2HH","executionInfo":{"status":"ok","timestamp":1706458265760,"user_tz":-540,"elapsed":7,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"b5c8aa7d-ef7f-48f4-a453-2f2eb1b38947"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}]},{"cell_type":"markdown","source":["## 2-3.Barebones PyTorch: Initialization\n","모델의 가중치 행렬을 초기화하는 몇 가지 유틸리티 메서드를 작성해 보겠습니다.\n","\n","- `random_weight(shape)`는 Kaiming normalization 방법으로 가중치 텐서를 초기화합니다.\n","- `zero_weight(shape)`는 모든 0으로 가중치 텐서를 초기화합니다. 바이어스 매개변수를 인스턴스화할 때 유용합니다.\n","\n","`random_weight` 함수는 Kaiming normal initialization 방법을 사용합니다:\n","\n","+ He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852\n","\n","- [Kaiming He Normal Initialization](https://imlim0813.tistory.com/25)   \n","$X\\sim N(0,\\sqrt{\\frac{2}{fan_{in}}}^2)$\n","\n"],"metadata":{"id":"46FRIyZkmf26"}},{"cell_type":"code","source":["# Kaiming He Normal Initialization\n","def random_weight(shape):\n","    \"\"\"\n","    Create random Tensors for weights; setting requires_grad=True means that we\n","    want to compute gradients for these Tensors during the backward pass.\n","    We use Kaiming normalization: sqrt(2 / fan_in)\n","    \"\"\"\n","    if len(shape)==2: # FC layer [in_nodes,out_nodes]\n","        fan_in=shape[0]\n","    else:\n","        fan_in=np.prod(shape[1:]) # Conv layer [out_channel,in_channel,kH, kW]\n","    # randn is standard normal distribution generator.\n","    w=torch.randn(shape,device=device,dtype=dtype)*np.sqrt(2./fan_in)\n","    w.requires_grad=True # we want to compute gradients for these Tensors\n","                         # during the backward pass\n","    return w"],"metadata":{"id":"Xm_d317xn6CC","executionInfo":{"status":"ok","timestamp":1706458265760,"user_tz":-540,"elapsed":5,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Zero Initialization\n","def zero_weight(shape):\n","    return torch.zeros(shape,device=device,dtype=dtype,requires_grad=True)"],"metadata":{"id":"MhkxfHACrvyL","executionInfo":{"status":"ok","timestamp":1706458266195,"user_tz":-540,"elapsed":4,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["random_weight((3,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbShq7AwsJVn","executionInfo":{"status":"ok","timestamp":1706458267325,"user_tz":-540,"elapsed":738,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"572f50f7-b0cc-4fbd-91ae-a664d27d1943"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.4821, -0.8642, -0.6294,  1.4611, -0.4378],\n","        [-0.0773, -0.7901,  0.1323, -0.6407,  0.8415],\n","        [ 0.0704,  1.5639, -0.0963,  1.1390, -0.1103]], device='cuda:0',\n","       requires_grad=True)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["zero_weight((3,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLJFXWODsSD6","executionInfo":{"status":"ok","timestamp":1706458267766,"user_tz":-540,"elapsed":6,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"4cf54276-62c0-45a1-f47a-1047fd727624"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]], device='cuda:0', requires_grad=True)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## 2-4.Barebones PyTorch: Check Accuracy\n","모델을 훈련할 때 다음 함수를 사용하여 훈련 또는 검증 세트에서 모델의 정확도를 확인합니다.\n","\n","정확도를 확인할 때 기울기를 계산할 필요가 없으므로 점수를 계산할 때 PyTorch가 계산 그래프를 만들 필요가 없습니다.  \n","그래프가 생성되는 것을 방지하기 위해 `torch.no_grad()` context manager에서 계산 범위를 지정합니다."],"metadata":{"id":"sNg4q_kHsViH"}},{"cell_type":"code","source":["from tqdm import tqdm\n","def check_accuracy_part2(loader,model_fn,params):\n","    \"\"\"\n","    Check the accuracy of a classification model.\n","\n","    Inputs:\n","    - loader: A DataLoader for the data split we want to check\n","    - model_fn: A function that performs the forward pass of the model,\n","      with the signature scores = model_fn(x, params)\n","    - params: List of PyTorch Tensors giving parameters of the model\n","\n","    Returns: Nothing, but prints the accuracy of the model\n","    \"\"\"\n","    split=None\n","    if loader.dataset.train:\n","        split='valid'\n","        if loader.sampler.indices[-1]+1==NUM_TRAIN:\n","            split='train'\n","    else:\n","        split='test'\n","    print('Checking accuracy on the [%s set]' % split,end=' ')\n","\n","    num_correct,num_samples=0,0\n","    with torch.no_grad():\n","        for x,y in tqdm(loader):\n","            x=x.to(device=device,dtype=dtype)\n","            y=y.to(device=device,dtype=torch.int64)\n","            scores=model_fn(x,params)\n","            _,preds=scores.max(1) # row에서 최댓값,인덱스\n","            num_correct+=(preds==y).sum()\n","            num_samples+=preds.size(0)\n","        acc=float(num_correct)/num_samples\n","        print(': %d / %d correct (%.2f%%)' % (num_correct,num_samples,100*acc))"],"metadata":{"id":"u9AVR-h0scjj","executionInfo":{"status":"ok","timestamp":1706458372409,"user_tz":-540,"elapsed":5,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## 2-5. BareBones PyTorch: Training Loop\n","이제 네트워크를 훈련하기 위한 basic training loop를 설정할 수 있습니다. momentum 없이 Stochastic gradient descent를 사용하여 모델을 훈련할 것입니다. 여기서는 `torch.functional.cross_entropy`를 사용하여 loss를 계산할 것입니다(http://pytorch.org/docs/stable/nn.html#cross-entropy).\n","\n","training loop는 신경망 함수, 초기화된 매개변수 목록(예제에서는 `[w1, w2]`), 학습 속도를 입력으로 받습니다."],"metadata":{"id":"2eQ7HnvSuj51"}},{"cell_type":"code","source":["def train_part2(model_fn,params,learning_rate):\n","    \"\"\"\n","    Train a model on CIFAR-10.\n","\n","    Inputs:\n","    - model_fn: A Python function that performs the forward pass of the model.\n","      It should have the signature scores = model_fn(x, params) where x is a\n","      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n","      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n","      scores for the elements in x.\n","    - params: List of PyTorch Tensors giving weights for the model\n","    - learning_rate: Python scalar giving the learning rate to use for SGD\n","\n","    Returns: Nothing\n","    \"\"\"\n","    for batch_idx,(x,y) in enumerate(loader_train):\n","        # Move the data to the proper device (GPU or CPU)\n","        x=x.to(device=device,dtype=dtype)\n","        y=y.to(device=device,dtype=torch.long)\n","\n","        # Forward pass: compute scores and loss\n","        scores=model_fn(x,params)\n","        loss=F.cross_entropy(scores,y)\n","\n","        # Backward pass:\n","        ## PyTorch figures out which Tensors in the computational\n","        ## graph has requires_grad=True and uses backpropagation to compute the\n","        ## gradient of the loss with respect to these Tensors, and stores the\n","        ## gradients in the .grad attribute of each Tensor.\n","        loss.backward()\n","\n","        # Update parameters:\n","        ## We don't want to backpropagate through the\n","        ## parameter updates, so we scope the updates under a torch.no_grad()\n","        ## context manager to prevent a computational graph from being built.\n","        with torch.no_grad():\n","            for w in params:\n","                w-=learning_rate*w.grad\n","                w.grad.zero_()  # Manually zero the gradients\n","\n","        if batch_idx%100==0:\n","            print('Iteration %d, loss = %.4f'%(batch_idx,loss.item()))\n","            check_accuracy_part2(loader_val,model_fn,params)\n","            check_accuracy_part2(loader_train,model_fn,params)\n","            print()"],"metadata":{"id":"QJkv4WSouq8s","executionInfo":{"status":"ok","timestamp":1706458375028,"user_tz":-540,"elapsed":3,"user":{"displayName":"노지예","userId":"16611815830350888933"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n","w2 = random_weight((hidden_layer_size, 10))\n","\n","train_part2(two_layer_fc, [w1, w2], learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2rcdvlRxc7o","executionInfo":{"status":"ok","timestamp":1706458511037,"user_tz":-540,"elapsed":134717,"user":{"displayName":"노지예","userId":"16611815830350888933"}},"outputId":"c59bb5c9-832d-40ad-b01c-e9ebe6299cf3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.2469\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 62.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 140 / 1000 correct (14.00%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:14<00:00, 53.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 6347 / 49000 correct (12.95%)\n","\n","Iteration 100, loss = 2.2558\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 43.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 299 / 1000 correct (29.90%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:16<00:00, 47.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 15422 / 49000 correct (31.47%)\n","\n","Iteration 200, loss = 2.0948\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 66.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 382 / 1000 correct (38.20%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:15<00:00, 50.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 19470 / 49000 correct (39.73%)\n","\n","Iteration 300, loss = 1.6720\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 61.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 422 / 1000 correct (42.20%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:13<00:00, 55.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 21408 / 49000 correct (43.69%)\n","\n","Iteration 400, loss = 2.0358\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 63.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 372 / 1000 correct (37.20%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:14<00:00, 52.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 20593 / 49000 correct (42.03%)\n","\n","Iteration 500, loss = 1.4718\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 48.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 451 / 1000 correct (45.10%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:14<00:00, 53.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 23115 / 49000 correct (47.17%)\n","\n","Iteration 600, loss = 1.7473\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 64.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 441 / 1000 correct (44.10%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:15<00:00, 50.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 23643 / 49000 correct (48.25%)\n","\n","Iteration 700, loss = 1.6942\n","Checking accuracy on the [valid set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 62.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 450 / 1000 correct (45.00%)\n","Checking accuracy on the [train set] "]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 766/766 [00:13<00:00, 56.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":[": 24134 / 49000 correct (49.25%)\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xG0CF7lL1w1A"},"execution_count":null,"outputs":[]}]}